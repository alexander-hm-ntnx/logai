{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Anomaly Detection on BGL dataset using LogBERT model\n",
    "This is a running example of an end-to-end workflow of Log Anomaly Detection on public dataset HDFS using the LogBERT model.\n",
    "\n",
    "There are similar workflows on the BGL datasets using other anomaly detectors (like LSTM based one in `bgl_lstm_unsupervised_parsed_sequential.ipynb`). \n",
    "\n",
    "The actual workflow script is exactly identical in these cases, except in the LogBERT case we choose to skip the log-parsing step. This is simply done following past literature, but there are no restrictions from the LogAI library side. \n",
    "\n",
    "\n",
    "Also check out the other config files that in this directory that cater to other datasets (HDFS), or other experimental configs like (parsing/nonparsing based, sliding/session window based log partitioning, sequential/semantic log feature representations, supervised/unsupervised setting, LSTM/CNN/Transformer/BERT model). \n",
    "\n",
    "To use these different experimental configs, you only need to point to the correct config file and the same workflow code should work perfectly for those!\n",
    "\n",
    "Only in case of changing the dataset (eg. from BGL to HDFS) you need to not only change the config.yaml file but also use the HDFSPreprocessor in the preprocessing step. Note that each custom dataset that are added should have its own Preprocessor class (which should inherit from logai.preproces.preprocessor.Preprocessor). \n",
    "\n",
    "For more complete explanations of each step of the workflow check out the `hdfs_lstm_unsupervised_parsed_sequential.ipynb` notebook instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from logai.applications.openset.anomaly_detection.openset_anomaly_detection_workflow import OpenSetADWorkflowConfig, validate_config_dict\n",
    "from logai.utils.file_utils import read_file\n",
    "from logai.utils.dataset_utils import split_train_dev_test_for_anomaly_detection\n",
    "import logging \n",
    "from logai.dataloader.data_loader import FileDataLoader\n",
    "from logai.preprocess.bgl_preprocessor import BGLPreprocessor\n",
    "from logai.information_extraction.log_parser import LogParser\n",
    "from logai.preprocess.openset_partitioner import OpenSetPartitioner\n",
    "from logai.analysis.nn_anomaly_detector import NNAnomalyDetector\n",
    "from logai.information_extraction.log_vectorizer import LogVectorizer\n",
    "from logai.utils import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"configs/bgl_logbert_config.yaml\"\n",
    "config_parsed = read_file(config_path)\n",
    "config_dict = config_parsed[\"workflow_config\"]\n",
    "config = OpenSetADWorkflowConfig.from_dict(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         RAS KERNEL INFO instruction cache parity error...\n",
      "1         RAS KERNEL INFO instruction cache parity error...\n",
      "2         RAS KERNEL INFO instruction cache parity error...\n",
      "3         RAS KERNEL INFO instruction cache parity error...\n",
      "4         RAS KERNEL INFO instruction cache parity error...\n",
      "                                ...                        \n",
      "358455    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358456    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358457    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358458    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358459    RAS KERNEL FATAL idoproxy communication failur...\n",
      "Name: logline, Length: 358460, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander.huang/Workspace/logai/logai/dataloader/data_loader.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected[constants.LOG_TIMESTAMPS] = pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "dataloader = FileDataLoader(config.data_loader_config)\n",
    "logrecord = dataloader.load_data()\n",
    "print (logrecord.body[constants.LOGLINE_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         RAS KERNEL INFO instruction cache parity error...\n",
      "1         RAS KERNEL INFO instruction cache parity error...\n",
      "2         RAS KERNEL INFO instruction cache parity error...\n",
      "3         RAS KERNEL INFO instruction cache parity error...\n",
      "4         RAS KERNEL INFO instruction cache parity error...\n",
      "                                ...                        \n",
      "358455    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358456    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358457    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358458    RAS KERNEL FATAL idoproxy communication failur...\n",
      "358459    RAS KERNEL FATAL idoproxy communication failur...\n",
      "Name: logline, Length: 358460, dtype: object\n"
     ]
    }
   ],
   "source": [
    "preprocessor = BGLPreprocessor(config.preprocessor_config)\n",
    "preprocessed_filepath = os.path.join(config.output_dir, 'BGL_11k_processed.csv')            \n",
    "logrecord = preprocessor.clean_log(logrecord)\n",
    "logrecord.save_to_csv(preprocessed_filepath)\n",
    "print (logrecord.body[constants.LOGLINE_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       RAS KERNEL INFO instruction cache parity error...\n",
      "1       RAS KERNEL INFO instruction cache parity error...\n",
      "2       RAS KERNEL INFO instruction cache parity error...\n",
      "3       RAS KERNEL INFO instruction cache parity error...\n",
      "4       RAS KERNEL INFO instruction cache parity error...\n",
      "                              ...                        \n",
      "1848    RAS APP FATAL ciod Error reading message prefi...\n",
      "1849    RAS KERNEL FATAL Lustre mount FAILED ALPHANUM ...\n",
      "1850    RAS KERNEL FATAL Lustre mount FAILED ALPHANUM ...\n",
      "1851    RAS KERNEL FATAL Lustre mount FAILED ALPHANUM ...\n",
      "1852    RAS KERNEL FATAL idoproxy communication failur...\n",
      "Name: logline, Length: 1853, dtype: object\n"
     ]
    }
   ],
   "source": [
    "partitioner = OpenSetPartitioner(config.open_set_partitioner_config)\n",
    "partitioned_filepath = os.path.join(config.output_dir, 'BGL_11k_nonparsed_session.csv')\n",
    "logrecord = partitioner.partition(logrecord)\n",
    "logrecord.save_to_csv(partitioned_filepath)\n",
    "print (logrecord.body[constants.LOGLINE_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices_train/dev/test:  32 4 1817\n",
      "Train/Dev/Test Anomalous 0 0 1808\n",
      "Train/Dev/Test Normal 32 4 9\n"
     ]
    }
   ],
   "source": [
    "train_filepath = os.path.join(config.output_dir, 'BGL_11k_nonparsed_session_unsupervised_train.csv')\n",
    "dev_filepath = os.path.join(config.output_dir, 'BGL_11k_nonparsed_session_unsupervised_dev.csv')\n",
    "test_filepath = os.path.join(config.output_dir, 'BGL_11k_nonparsed_session_unsupervised_test.csv')\n",
    "\n",
    "(train_data, dev_data, test_data) = split_train_dev_test_for_anomaly_detection(\n",
    "                logrecord,training_type=config.training_type,\n",
    "                test_data_frac_neg_class=config.test_data_frac_neg,\n",
    "                test_data_frac_pos_class=config.test_data_frac_pos,\n",
    "                shuffle=config.train_test_shuffle\n",
    "            )\n",
    "\n",
    "train_data.save_to_csv(train_filepath)\n",
    "dev_data.save_to_csv(dev_filepath)\n",
    "test_data.save_to_csv(test_filepath)\n",
    "print ('Train/Dev/Test Anomalous', len(train_data.labels[train_data.labels[constants.LABELS]==1]), \n",
    "                                   len(dev_data.labels[dev_data.labels[constants.LABELS]==1]), \n",
    "                                   len(test_data.labels[test_data.labels[constants.LABELS]==1]))\n",
    "print ('Train/Dev/Test Normal', len(train_data.labels[train_data.labels[constants.LABELS]==0]), \n",
    "                                   len(dev_data.labels[dev_data.labels[constants.LABELS]==0]), \n",
    "                                   len(test_data.labels[test_data.labels[constants.LABELS]==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3704fd739b49338679f7f58a67b36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7bbdab51594f58b069317808ed09a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1020ae6a47a410dab4ad12804937263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1817 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 32\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "vectorizer = LogVectorizer(config.log_vectorizer_config)\n",
    "vectorizer.fit(train_data)\n",
    "train_features = vectorizer.transform(train_data)\n",
    "dev_features = vectorizer.transform(dev_data)\n",
    "test_features = vectorizer.transform(test_data)\n",
    "print (train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized data collator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "/Users/alexander.huang/Workspace/logai/venv/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 32\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f75dad7c364b5aa8df504e7f9fe10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9481, 'learning_rate': 8.75e-05, 'epoch': 1.25}\n",
      "{'loss': 3.5514, 'learning_rate': 7.500000000000001e-05, 'epoch': 2.5}\n",
      "{'loss': 3.139, 'learning_rate': 6.25e-05, 'epoch': 3.75}\n",
      "{'loss': 2.9058, 'learning_rate': 5e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7939, 'learning_rate': 3.7500000000000003e-05, 'epoch': 6.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a15063e353c49e3ba59ab09177fefe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-50\n",
      "Configuration saved in temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-50/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.910862445831299, 'eval_runtime': 0.1782, 'eval_samples_per_second': 22.441, 'eval_steps_per_second': 5.61, 'epoch': 6.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-50/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2386, 'learning_rate': 2.5e-05, 'epoch': 7.5}\n",
      "{'loss': 1.7941, 'learning_rate': 1.25e-05, 'epoch': 8.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1435, 'learning_rate': 0.0, 'epoch': 10.0}\n",
      "{'train_runtime': 42.8749, 'train_samples_per_second': 7.464, 'train_steps_per_second': 1.866, 'train_loss': 2.8143080949783323, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "anomaly_detector = NNAnomalyDetector(config=config.nn_anomaly_detection_config)\n",
    "anomaly_detector.fit(train_features, dev_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading model from /Users/alexander.huang/Workspace/logai/examples/jupyter_notebook/nn_ad_benchmarking/temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-50\n",
      "loading configuration file /Users/alexander.huang/Workspace/logai/examples/jupyter_notebook/nn_ad_benchmarking/temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-50/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 332\n",
      "}\n",
      "\n",
      "loading weights file /Users/alexander.huang/Workspace/logai/examples/jupyter_notebook/nn_ad_benchmarking/temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-50/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at /Users/alexander.huang/Workspace/logai/examples/jupyter_notebook/nn_ad_benchmarking/temp_output/BGL_11k_parsed_session_supervised_AD/bert-base-cased/checkpoint-50.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378979d37527433c9419db2b6b266ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1817 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1867\n",
      "  Batch size = 256\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08069db43b4d47628673ebf50b36985b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.928493022918701 test_runtime: 53.9503 test_samples/s: 34.606\n",
      "INFO:root:number of original test instances 1481\n",
      "INFO:root:loss_mean Pos scores:  mean: 6.956572309020314, std: 0.6080354536980397\n",
      "INFO:root:loss_mean Neg scores: mean: 3.0824834387871176, std: 1.6453940559119908\n",
      "INFO:root:AUC of loss_mean: 0.9982179226069247\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_max Pos scores:  mean: 8.256480937253352, std: 0.35247602095338415\n",
      "INFO:root:loss_max Neg scores: mean: 4.885785311460495, std: 2.3674712402659304\n",
      "INFO:root:AUC of loss_max: 0.9978784792939579\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_top6_mean Pos scores:  mean: 7.644149760391735, std: 0.3221544536587862\n",
      "INFO:root:loss_top6_mean Neg scores: mean: 3.615651013329625, std: 1.9612775925279653\n",
      "INFO:root:AUC of loss_top6_mean: 0.9996605566870332\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_prob Pos scores:  mean: 0.843062021000963, std: 0.0006618899932966818\n",
      "INFO:root:scores_top6_max_prob Neg scores: mean: 0.7798267786080639, std: 0.08485450280961808\n",
      "INFO:root:AUC of scores_top6_max_prob: 0.5767141887304821\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_min_logprob Pos scores:  mean: 1.8519501883496954, std: 0.004218893563392789\n",
      "INFO:root:scores_top6_min_logprob Neg scores: mean: 1.5994890301177898, std: 0.33519117595802245\n",
      "INFO:root:AUC of scores_top6_min_logprob: 0.5767141887304821\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_entropy Pos scores:  mean: 3.727425217682432, std: 0.0016150056699090764\n",
      "INFO:root:scores_top6_max_entropy Neg scores: mean: 3.3370424906412763, std: 0.5064776795737281\n",
      "INFO:root:AUC of scores_top6_max_entropy: 0.5980991174473863\n",
      "INFO:root:\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1867\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e609abd2044ecb967619a4ff506460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.927598476409912 test_runtime: 53.3697 test_samples/s: 34.982\n",
      "INFO:root:number of original test instances 1543\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1867\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2a4eeba7d244fab28d7db114f72a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.944589138031006 test_runtime: 52.7862 test_samples/s: 35.369\n",
      "INFO:root:number of original test instances 1586\n",
      "INFO:root:loss_mean Pos scores:  mean: 6.960877492884767, std: 0.3125803434389781\n",
      "INFO:root:loss_mean Neg scores: mean: 3.116841279288272, std: 1.619121324586434\n",
      "INFO:root:AUC of loss_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_max Pos scores:  mean: 8.568647076723996, std: 0.3393042668344223\n",
      "INFO:root:loss_max Neg scores: mean: 5.053523451089859, std: 2.2668106463743003\n",
      "INFO:root:AUC of loss_max: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_top6_mean Pos scores:  mean: 7.650102574703828, std: 0.18209936760463388\n",
      "INFO:root:loss_top6_mean Neg scores: mean: 3.632692766893241, std: 1.959059970462125\n",
      "INFO:root:AUC of loss_top6_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_prob Pos scores:  mean: 0.8430962857866755, std: 0.00039696159249113367\n",
      "INFO:root:scores_top6_max_prob Neg scores: mean: 0.7852794508863654, std: 0.07493434039226053\n",
      "INFO:root:AUC of scores_top6_max_prob: 0.6854404309252218\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_min_logprob Pos scores:  mean: 1.852165794186635, std: 0.0025223882230854568\n",
      "INFO:root:scores_top6_min_logprob Neg scores: mean: 1.609491161795126, std: 0.3141949319752749\n",
      "INFO:root:AUC of scores_top6_min_logprob: 0.6852820025348542\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_entropy Pos scores:  mean: 3.7275170158037185, std: 0.0013925425710830913\n",
      "INFO:root:scores_top6_max_entropy Neg scores: mean: 3.3604123849007816, std: 0.4744688347049092\n",
      "INFO:root:AUC of scores_top6_max_entropy: 0.6974017743979721\n",
      "INFO:root:\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1867\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48a5dfa6273420aa2bae4e8e9aa988e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.970725059509277 test_runtime: 53.6928 test_samples/s: 34.772\n",
      "INFO:root:number of original test instances 1642\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1867\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1113fb690fc4f128d28b4293d9f8bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.930238723754883 test_runtime: 53.205 test_samples/s: 35.091\n",
      "INFO:root:number of original test instances 1694\n",
      "INFO:root:loss_mean Pos scores:  mean: 6.973155573297613, std: 0.27860316832100634\n",
      "INFO:root:loss_mean Neg scores: mean: 3.0994350669005373, std: 1.5537590110223798\n",
      "INFO:root:AUC of loss_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_max Pos scores:  mean: 8.619907401506554, std: 0.3353480344539885\n",
      "INFO:root:loss_max Neg scores: mean: 4.948211563958062, std: 2.151513058115627\n",
      "INFO:root:AUC of loss_max: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_top6_mean Pos scores:  mean: 7.674706078963118, std: 0.17001428601839375\n",
      "INFO:root:loss_top6_mean Neg scores: mean: 3.6250014551627783, std: 1.8839540175865472\n",
      "INFO:root:AUC of loss_top6_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_prob Pos scores:  mean: 0.8431832878216684, std: 0.00034071575384181786\n",
      "INFO:root:scores_top6_max_prob Neg scores: mean: 0.7914862497445242, std: 0.07365872379765771\n",
      "INFO:root:AUC of scores_top6_max_prob: 0.6350807781074843\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_min_logprob Pos scores:  mean: 1.8527195957463212, std: 0.0021637782471844932\n",
      "INFO:root:scores_top6_min_logprob Neg scores: mean: 1.6396709545894905, std: 0.3035043875356518\n",
      "INFO:root:AUC of scores_top6_min_logprob: 0.6387734915924828\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_entropy Pos scores:  mean: 3.7276179445670303, std: 0.0013891103656206464\n",
      "INFO:root:scores_top6_max_entropy Neg scores: mean: 3.4002540919515827, std: 0.4635058534158999\n",
      "INFO:root:AUC of scores_top6_max_entropy: 0.6532805802835475\n",
      "INFO:root:\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1867\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452e7aacf5d94f4ab56e28e284ad3648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.954885482788086 test_runtime: 54.2889 test_samples/s: 34.39\n",
      "INFO:root:number of original test instances 1747\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1867\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f10650bb9fb4ec88bf5aed07e5f262b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.891811370849609 test_runtime: 54.86 test_samples/s: 34.032\n",
      "INFO:root:number of original test instances 1772\n",
      "INFO:root:loss_mean Pos scores:  mean: 6.975145703049782, std: 0.2607007075216614\n",
      "INFO:root:loss_mean Neg scores: mean: 3.1087315424699193, std: 1.551414920839871\n",
      "INFO:root:AUC of loss_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_max Pos scores:  mean: 8.648724076156919, std: 0.3322655258187494\n",
      "INFO:root:loss_max Neg scores: mean: 4.97110030386183, std: 2.1251133063303382\n",
      "INFO:root:AUC of loss_max: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_top6_mean Pos scores:  mean: 7.727370514145509, std: 0.14610120517657663\n",
      "INFO:root:loss_top6_mean Neg scores: mean: 3.692090356239566, std: 1.883234391886213\n",
      "INFO:root:AUC of loss_top6_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_prob Pos scores:  mean: 0.8433170856274405, std: 0.0002551948758332728\n",
      "INFO:root:scores_top6_max_prob Neg scores: mean: 0.7955843684390004, std: 0.0677194366331644\n",
      "INFO:root:AUC of scores_top6_max_prob: 0.6580323942774312\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_min_logprob Pos scores:  mean: 1.8535734634331569, std: 0.0016228045002871548\n",
      "INFO:root:scores_top6_min_logprob Neg scores: mean: 1.655391780866517, std: 0.2812165793076369\n",
      "INFO:root:AUC of scores_top6_min_logprob: 0.6584735614798009\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_entropy Pos scores:  mean: 3.7278515503741154, std: 0.0012940495547331188\n",
      "INFO:root:scores_top6_max_entropy Neg scores: mean: 3.4028474026256137, std: 0.4600017154631556\n",
      "INFO:root:AUC of scores_top6_max_entropy: 0.6845654503056658\n",
      "INFO:root:\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1866\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6b4d74a0774984a3233f645c67cba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.974289417266846 test_runtime: 55.0723 test_samples/s: 33.883\n",
      "INFO:root:number of original test instances 1801\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1866\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcdf715a9a2d4983bc6caa60f5abdeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.930877685546875 test_runtime: 347.9693 test_samples/s: 5.363\n",
      "INFO:root:number of original test instances 1813\n",
      "INFO:root:loss_mean Pos scores:  mean: 6.981966105960047, std: 0.24387351536445512\n",
      "INFO:root:loss_mean Neg scores: mean: 3.1068283653285667, std: 1.5511973716441778\n",
      "INFO:root:AUC of loss_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_max Pos scores:  mean: 8.668997799477927, std: 0.3331098104219032\n",
      "INFO:root:loss_max Neg scores: mean: 4.980885664621989, std: 2.1147806726719143\n",
      "INFO:root:AUC of loss_max: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:loss_top6_mean Pos scores:  mean: 7.776402157923218, std: 0.11800260476669419\n",
      "INFO:root:loss_top6_mean Neg scores: mean: 3.706846517545206, std: 1.8740946036341497\n",
      "INFO:root:AUC of loss_top6_mean: 1.0\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_prob Pos scores:  mean: 0.8433658191870901, std: 0.0002228806073072557\n",
      "INFO:root:scores_top6_max_prob Neg scores: mean: 0.7968413198803678, std: 0.06583845451870429\n",
      "INFO:root:AUC of scores_top6_max_prob: 0.6672209903917221\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_min_logprob Pos scores:  mean: 1.8538878999182409, std: 0.0014166285354030687\n",
      "INFO:root:scores_top6_min_logprob Neg scores: mean: 1.6600965366319373, std: 0.2741829821313237\n",
      "INFO:root:AUC of scores_top6_min_logprob: 0.667528948016753\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:scores_top6_max_entropy Pos scores:  mean: 3.7279336404733603, std: 0.0012679747206792813\n",
      "INFO:root:scores_top6_max_entropy Neg scores: mean: 3.4026262252419084, std: 0.4603710534991905\n",
      "INFO:root:AUC of scores_top6_max_entropy: 0.7006651884700665\n",
      "INFO:root:\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1866\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544e945ca970481a9719b44f96168791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test_loss: 6.982187271118164 test_runtime: 54.1155 test_samples/s: 34.482\n",
      "INFO:root:number of original test instances 1817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      indices  max_loss   sum_loss num_loss  \\\n",
      "0           0  1.788414   8.479586        9   \n",
      "1           0   1.91644   9.006147        8   \n",
      "2           1  2.114819   9.054378        8   \n",
      "3           2  2.682362  10.225121        8   \n",
      "4           3  7.217087  47.702454        9   \n",
      "...       ...       ...        ...      ...   \n",
      "18662    1813  8.931251   63.58242        8   \n",
      "18663    1814  8.526834  69.759872        9   \n",
      "18664    1814  8.944598  64.604271        8   \n",
      "18665    1815  8.536341   61.96146        8   \n",
      "18666    1816  8.256463  60.937569        8   \n",
      "\n",
      "                                               top6_loss  \\\n",
      "0      [1.788413643836975, 1.7165228128433228, 1.0566...   \n",
      "1      [1.9164402484893799, 1.7673128843307495, 1.688...   \n",
      "2      [2.114818572998047, 1.5756577253341675, 1.5471...   \n",
      "3      [2.6823620796203613, 1.5462324619293213, 1.351...   \n",
      "4      [7.2170867919921875, 6.036893844604492, 5.8234...   \n",
      "...                                                  ...   \n",
      "18662  [8.93125057220459, 8.535402297973633, 8.096324...   \n",
      "18663  [8.526833534240723, 8.10704231262207, 8.090286...   \n",
      "18664  [8.944598197937012, 8.520166397094727, 8.15112...   \n",
      "18665  [8.536340713500977, 8.109248161315918, 8.09384...   \n",
      "18666  [8.256463050842285, 8.096747398376465, 7.84976...   \n",
      "\n",
      "                                           top6_max_prob  \\\n",
      "0      [0.16722524166107178, 0.18517428636550903, 0.3...   \n",
      "1      [0.18281219899654388, 0.1847277134656906, 0.28...   \n",
      "2      [0.23071011900901794, 0.2911660969257355, 0.31...   \n",
      "3      [0.1856776624917984, 0.2581976354122162, 0.258...   \n",
      "4      [0.1561335325241089, 0.15652772784233093, 0.15...   \n",
      "...                                                  ...   \n",
      "18662  [0.15639056265354156, 0.1572287231683731, 0.15...   \n",
      "18663  [0.15508121252059937, 0.1554521769285202, 0.15...   \n",
      "18664  [0.1565171331167221, 0.15685498714447021, 0.15...   \n",
      "18665  [0.15498994290828705, 0.15501217544078827, 0.1...   \n",
      "18666  [0.15500353276729584, 0.15625135600566864, 0.1...   \n",
      "\n",
      "                                        top6_min_logprob  \\\n",
      "0      [1.788413643836975, 1.6864577531814575, 1.0566...   \n",
      "1      [1.6992958784103394, 1.6888723373413086, 1.263...   \n",
      "2      [1.4665932655334473, 1.2338613271713257, 1.163...   \n",
      "3      [1.6837431192398071, 1.354029893875122, 1.3518...   \n",
      "4      [1.8570436239242554, 1.8545221090316772, 1.854...   \n",
      "...                                                  ...   \n",
      "18662  [1.8553988933563232, 1.8500536680221558, 1.848...   \n",
      "18663  [1.8638063669204712, 1.8614171743392944, 1.859...   \n",
      "18664  [1.854589819908142, 1.8524335622787476, 1.8488...   \n",
      "18665  [1.864395022392273, 1.8642516136169434, 1.8629...   \n",
      "18666  [1.8643072843551636, 1.856289267539978, 1.8496...   \n",
      "\n",
      "                                        top6_max_entropy  \n",
      "0      [3.1013362407684326, 2.8874855041503906, 2.696...  \n",
      "1      [3.186615467071533, 2.90974497795105, 2.874079...  \n",
      "2      [2.916484832763672, 2.895962715148926, 2.71177...  \n",
      "3      [3.0645527839660645, 2.9212424755096436, 2.801...  \n",
      "4      [3.7291500568389893, 3.728231906890869, 3.7271...  \n",
      "...                                                  ...  \n",
      "18662  [3.730642080307007, 3.728147506713867, 3.72773...  \n",
      "18663  [3.731588363647461, 3.7314932346343994, 3.7308...  \n",
      "18664  [3.7296195030212402, 3.7292773723602295, 3.729...  \n",
      "18665  [3.7305397987365723, 3.7298710346221924, 3.728...  \n",
      "18666  [3.7307045459747314, 3.728160858154297, 3.7279...  \n",
      "\n",
      "[18667 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "predict_results = anomaly_detector.predict(test_features)\n",
    "print (predict_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
